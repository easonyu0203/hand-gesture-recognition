{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "torchvision.transforms.transforms.ToTensor is not a Module subclass",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[27], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m dataset \u001B[38;5;241m=\u001B[39m MediaGestureDataset()\n\u001B[1;32m      9\u001B[0m net: HandGesRecNet \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./trained_nets/hand_ges_rec_net\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 10\u001B[0m net\u001B[38;5;241m.\u001B[39mtransform \u001B[38;5;241m=\u001B[39m \u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSequential\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43mToTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m        \u001B[49m\u001B[43mBasicTransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m        \u001B[49m\u001B[43mNormalizeMaxSpan\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m        \u001B[49m\u001B[43mWristAsOrigin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# feat, label = dataset[0]\u001B[39;00m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# traned_feat = net.transform(feat)\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# with torch.no_grad():\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# pred_label_name = [net.label_idx_to_name[i.item()] for i in preds_idxs]\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# pred_label_name\u001B[39;00m\n",
      "File \u001B[0;32m~/Developer/Projects/intern/glowing/mocap-research/hand-gesture-recognition/venv/lib/python3.9/site-packages/torch/nn/modules/container.py:91\u001B[0m, in \u001B[0;36mSequential.__init__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m     89\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     90\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m idx, module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(args):\n\u001B[0;32m---> 91\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43midx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodule\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Developer/Projects/intern/glowing/mocap-research/hand-gesture-recognition/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:444\u001B[0m, in \u001B[0;36mModule.add_module\u001B[0;34m(self, name, module)\u001B[0m\n\u001B[1;32m    434\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Adds a child module to the current module.\u001B[39;00m\n\u001B[1;32m    435\u001B[0m \n\u001B[1;32m    436\u001B[0m \u001B[38;5;124;03mThe module can be accessed as an attribute using the given name.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    441\u001B[0m \u001B[38;5;124;03m    module (Module): child module to be added to the module.\u001B[39;00m\n\u001B[1;32m    442\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(module, Module) \u001B[38;5;129;01mand\u001B[39;00m module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 444\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m is not a Module subclass\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    445\u001B[0m         torch\u001B[38;5;241m.\u001B[39mtypename(module)))\n\u001B[1;32m    446\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(name, torch\u001B[38;5;241m.\u001B[39m_six\u001B[38;5;241m.\u001B[39mstring_classes):\n\u001B[1;32m    447\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodule name should be a string. Got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    448\u001B[0m         torch\u001B[38;5;241m.\u001B[39mtypename(name)))\n",
      "\u001B[0;31mTypeError\u001B[0m: torchvision.transforms.transforms.ToTensor is not a Module subclass"
     ]
    }
   ],
   "source": [
    "from datasets.transformations import BasicTransform, NormalizeMaxSpan, WristAsOrigin\n",
    "from torchvision.transforms import ToTensor\n",
    "from datasets.media_gesture import MediaGestureDataset\n",
    "from nets.hand_ges_rec_net import HandGesRecNet\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "dataset = MediaGestureDataset()\n",
    "net: HandGesRecNet = torch.load(\"./trained_nets/hand_ges_rec_net\")\n",
    "net.transform = nn.Sequential(\n",
    "    ToTensor(),\n",
    "        BasicTransform(),\n",
    "        NormalizeMaxSpan(1),\n",
    "        WristAsOrigin()\n",
    "    )\n",
    "net.save(\"./trained_nets/hand_ges_rec_net\")\n",
    "# feat, label = dataset[0]\n",
    "# traned_feat = net.transform(feat)\n",
    "# with torch.no_grad():\n",
    "#     preds = net(traned_feat.unsqueeze(0))\n",
    "# preds_idxs = preds.argmax(1)\n",
    "# confidence = torch.gather(nn.Softmax(dim=1)(preds), 1, preds_idxs.unsqueeze(1)) * 100\n",
    "# pred_label_name = [net.label_idx_to_name[i.item()] for i in preds_idxs]\n",
    "# pred_label_name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
